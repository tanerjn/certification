AWS DevOps Pro(Dumpsgate-2)

- Artefacts: Publish the application artefacts to an Amazon S3 bucket, create VPC endpoint for S3. Assign IAM profile to the EC2 instances so they can read the application artefacts from the S3 bucket.
- Patching: System Manager Parameter Store to securely store credentials for each Linux and Windows server. System Manager Resource Group to remotely deploy patch updates using Parameter Store.
- Logging: Kinesis Firehose + Kinesis Data Streams to write logs to Amazon ES in the auditing account. Create CloudWatch subscription filter and stream logs from sub accounts to the Kinesis stream in the auditing account.
- Grid memory: Adding new nodes /etc/cluster/nodes.config listing the IP addresses of current mode. OpsWorks stacks to layer the server nodes of the cluster. Chef recipe that populates the content of the /etc/cluster/nodes.config file and restarts the service by using the current members of the layer. Assign the recipe to the Configure lifecycle event.
- Tagging and configuration: AWS Config record config changes and output the data to S3 bucket. QuickSight analysis of the dataset, and use the information on dashboards and mobile devices.
- EC2 ASG automation: Cloud Watch Logs subscription in an Lambda function. Configure the function to add a tag to the EC2 instance that produced the login event and mark the instance to be decommissioned. CloudWatch Events rule to trigger a daily Lambda function that terminates all the instances with tag.
- Canary testing: create a classic load balancer and AutoScaling group for blue/green environments. Use Amazon Route 53 and create weighted A records on Classic Load Balancer.
- Across multiple AZ: use Aurora with read replicas for the product catalog and additional local Aurora instances in each region for the customer information and purchases.
- Audit cost and automate infrastructure:  create CloudWatch events rule with Trusted Advisor as the source for low utilisation EC2 instances. Trigger Lambda function that filters out reported data based on tags for each team, environment, cost and store the Lambda function in S3. Set up second trigger to initiate Lambda function to reduce to underutilised instances. 
- Hybrid architecture solution in which some legacy systems remain on-premises while a specific cluster of servers moved to AWS. Reusable CloudFormation to manage EC2 ASG minimum 1 and maximum 1. Give the hostname Elastic Network Interface and AZ as stack parameter. 
- New tasks are running with old image: Restart the ECS agent.
- Security hardened AMI: Install the inspector agent in each AMI. Configure AWS Step functions to launch an EC2 instance for each operating system from the hardened AMI, tag the instance SecurityCheck:True. Once the instances are booted StepFunctions will trigger Inspector assessment for all instances with the tag security check.
- Restrict the push: Additional policy to include a deny rule for the codeCommit:GitPush. 
- CD workflow: CodeCommit: development branch to hold merged changes. Use CodeBuild to build and test the code in the development branch triggered on a new commit. Merge to the master and deploy to  production by using CodeDeploy.
- Sudden spikes: in a website load times. Check Egress security group rules and network ACLs for the VPC, check FlowLogs.
- Resilient and highly available: Elastic Beanstalk with a custom AMI including all web components. Deploy the platform by using an AutoScaling group behind AutoScaling. Use Route53 to point the application DNS record to the Elastic Beanstalk load balancer.
    - Remove AWS credentials from the environment variable.
    - Store DB_PASSWORD at safe. 
    - Use Systems Manager run command versus scp and ssh directly to the instance.
- Minimal operational effort: Implement Lambda function to read the list of proxy IP addresses from the S3 object.
- Implement Lambda function to read the list of proxy IP addresses from the S3 object and update the ELB security group to allow HTTPS only from the given IP addresses.
- Configure the S3 bucket to invoke the lambda function when the object is updated. Save the IP address list to the S3 bucket when they are changed.
- CodePipeline automation: All rejected or failed approval actions across all the pipelines.
- Launch ec2 m4 small and run script on it to check for new AMIs. If new AMIs are available, the script should update the launch configuration resource block with the new AMI ID.
- Launch the application from the CloudFormation template in the second region, which sets the capacity of the ASG group to 1. Create RDS read replica in the second region. In the second region, enable cross region replication between the original S3 bucket and a new S3 bucket. To fail over, promote the read replica as master. Update the CloudFormation stack and increase the capacity of the ASG.
- Run the application in Beanstalk with the deployment policy set to immutable. Deploy the lambda functions, DynamoDB tables, and Amazon ES domain with an CloudFormation template. Deploy the web application, Lambda functions, DynamoDB tables and Amazon ES domain in an AWS CloudFormation template. Deploy changes with an CodeDeploy blue/green deployment. 
- Media customer: least amount of steps to integrate with Slack. Integrate personal health dashboard with CloudWatch events which can invoke Lambda functions and send to Slack channel.
- Disaster recovery exercise: RTO / RPO improvement in cross region failover. Use SNS topics to receive published messages from RDS to snapshot a DB instance, create cross region snapshot copy and restore an instance from the snapshot. Use a scheduled Amazon CloudWatch events rule at a frequency matching the RPO trigger the Lambda function to snapshot a database instance. Trigger the Lambda function to create cross region snapshots when SNS topic receives messages. Configure Lambda function to restore an instance from a snapshot to trigger sending new messages published to the availability SNS topic.
- Security audit without EBS encrytpion: Create CloudFormation template that adds an AWS config managed rule for EBS encryption. Use a CloudFormation stack set to deploy the template across all accounts and regions. Store consolidated evaluation results from config rules in S3. Send notification using SNS when non-compliant resources are detected.
- Shipping orders dynamoDB. Item count to Kinesis. Logs-> Lambda functions are throttling error. Create fourth Lambda function and configure it to be the only Lambda reading from the stream. Then use it to pass the payload to the other three Lambda functions.
- Government agency storing confidential files in S3 bucket. Agency has configured federated access with AD user group to this bucket: Configure AWS Config rule to detect the configuration change and execute a Lambda to revert the change.
- Healthcare provider has hybrid architecture: includes 120 on-premise VMware running RedHat and 50 EC2 instances. Install Systems Manager agents on both the on-premises virtual machines and the EC2 instances. Enable inventory collection and configure resource data sync to an S3 bucket to analyse the data with Athena.
- Download and integrate the latest ISO Linux2 and execute the application deployment on the resulting server. Confirm all tests are consistent.
- Deployment in the new country: Code updates as commits to feature branch. Merge the commits to a release branch as features ready.
- Deploy with zero downtime: CloudFormation and Route53 record, ALB, DynamoDB, ASG. Active instance serving: AutoScaling:AutoScalingGroup:UpdatePolicy attribute with zero downtime policy. New application load balancer and AutoScaling group. Use route 53 to change the active ALB.
- AMI creation: Launch EC2 and install packer, configure packer with values defining how the image should be created. Build Jenkins pipeline to invoke the Packer build when triggered to build an AMI store. Store the AMI identification output in the DynamoDB.
- Requests are going to old ALB. Create two target groups named Blue and Green . Create a rule on the ALB pointed to a single target. Add logic to the deployment to the target group of the newly deployed ASG.
- Microservices running in Lambda read data from DynamoDB. New version of each service should be shifted incrementally. Create CodePipeline config and set up source code step to trigger when code is pushed. Set up build step to use CodeBuild to run tests, then the important CodeDeploy 10 percent every 3 minutes option.
- Production, staging and development. CodePipeline multiple stages, Lambda function to trigger CloudFormation deployments dynamically alter the UserData of the EC2 instances launched in each environment.
- Application runs behind LoadBalancer. RDS MySQL. 
- RTO/RPO improvement: Launch a replica stack of everything except RDS in different region. Create an RDS in new region and configure the new stack to the point the local RDS instance. Add new route to failover set.
- Subject as the primary key and ForumName)S3, EC2, RDS) as the sort key. Have the LSI and LastPostDate as the sort key.
- CloudFormation to deploy a three tier web application stores data in RDS MySQL Multi AZ instance. Engineer should update the EngineVersion property of the AWS::RDS::DBInstance resource type in the CloudFormation template to the latest desired version. Launch a second stack and make the new RDS  instance read replica.
- OpsWorks restarting instances for no reason: Create SNS topic and create subscription for this topic that contains the destination email address. See when the instance is unavailable: Create CloudWatch rule: specify aws.opsworks as a source and specify auto-healing the initiated-by details. Use SNS topic as target.
- Least administrative overhead: AWS Config: Identify all EC2 instances to be audited by ConfigRecording on all EC2 resources for the region. Create custom Config rule that triggers an Lambda function by using the “config-rule-change-triggered” blueprint. Modify the Lambda evaluateCompliance function to verify host placement to return a NON_COMPLIANT result if the instance is not running on an EC2 dedicated host. Use AWS Config to report to address noncompliant instances.
- S3 buckets contain encrypted secrets should be made by a trusted group of admins. Real-time automated checks to meet the requierement. Lambda triggered by S3 data events for object changes and the IAM user’s membership in an admin role.
- 5 independent Lambda functions in CodePipeline and CodeBuild deploys each Lambda in sequence. CloudWatch events ensure execution starts as quickly as possible after a change is made. Increase speed: Lambda function in parallel by runOrder.
- Version control of the CloudFormation: cross stack references in CloudFormation, and maintain several templates in version control.
- Easy rollbacks: Deploy using Beanstalk, connect to an external RDS MySQL using Beanstalk environment properties. Use Beanstalk immutable updates for application deployments.
- Error at S3 bucket read: Access denied at VPC: S3 bucket policy, VPC endpoint policy, IAM role configuration.
- Segmented architecture: Collect system Logs and application logs by using CloudWatch logs agent. Store all logs in S3 bucket in central account. Set up an S3 trigger and an Lambda function to analyse incoming logs and automatically identify anomalies. Amazon Athena to run ad hoc queries on the logs in the central account. Question 46
- CloudWatch logs to trigger lambda function. S3 analyse incoming logs. Athena to run queries in the log.
- Canary 10 percent in 5 minutes
- CodeDeploy MinimumHealthyHosts.
- SystemManager for Windows machines: IAM service role for Systemmanager ssm.amazonaws.com to execute AssumeRole. Previously obtained activation code and activation IDS, download and install SSM Agent Hybrid instances show with -mi prefix. 
- DNS failover for distributed web application disaster recovery. Configure Route 53 to provide DNS routing. Ensure firewall and routing rules, proxy. Governing amazon route set it to failover distribute traffic DNS entries. 
- ECS Cluster: awslogs, ALB to point S3, Kinesis Firehose to destination CloudWatch subscription.
- ECS Cluster to run workloads on the cluster with ALB on the front end, using multiple target groups. Collect logs and send to S3 bucket. Install CloudWatch logs logging on the ECs instances, change logging to awslogs. Enable access loging on the ALB and point it directly to  S3 logging. Create Kinesis Firehose with destination S3.
- CodeDeploy CloudWatch events rule to send SNS message when deployment fails. CodeDeploy to automatically rollback when the deployment fails.
- Launch EC2 instances with an EC2 IAM role to access AWS services. Retrieve the DB credentials from Secrets Manager.
- Deployment Strategy: Preconfigure the AMI by installing all the software using Systems Manager and configure Auto Scaling tag the instances at launch with their specific environment. Use a bootstrap script in user data to read the tags and configure for the environment. Use Systems Manager Store for the secrets using KMS.
- ELB check instance termination: AutoScaling lifecycle hooks to put instances in a Terminating:Wait state. Create an CloudWatch Events rule for EC2 instance terminate lifecycle action.
- Use DynamoDB accelerator to cache repeated read requests to DynamoDB and Amazon CloudFront to cache images stored in S3.
- 200 server nodes concurrently: upload licences to DynamoDB. Create script to launch the servers by using the parameter —count, with min:max instances to launch. In the user data script, acquire an available license from the DynamoDB table, monitor each instance and in case of failure replace the instance and manually update the DynamoDB.
- Static website on S3: Deletion has failed bec. S3 bucket is not empty. Modify custom resources Lambda function code to recursively empty the bucket when RequestType is Delete.
- Deploy to multiple regions. Any update to the code repo triggers two stage build and deployment pipeline. One region successful deployment invokes the lambda function to copy the build artefacts to an S3 bucket in another region. After the arfefact is copied it triggers a deployment pipeline in the new region.
- Create alias for lambda pointing to the Lambda endpoints for the old and new versions. Configure route 53 to route %10 of incoming traffic to the new version. New version becomes stable-> update the alias to route all traffic to the new one. API GW, create canary release deployment by adding canary settings to the stage of a regular deployment. Configure API GW to route %10 of the incoming traffic to the canary release. Canary release gets stable->promote it to production.
- Security code analysis: CodePipeline to create a pipeline then create a custom action type. Create job worker for the on premises server that polls CodePipeline for job requests initiates the tests and returns the results. Configure the pipeline to invoke the custom action after the source stage.
- Apache app to CodeDeploy env var DEPLOYMENT_GROUP_NAME configure log level settings reference script BeforeInstall lifecycle. 
- Chef recipes stored in private git: Configure OpsWorks stacks and use custom Chef cookbooks. Add layer in OpsWorks for the Node.js application. Configure time based instances and attach an EC2 IAM role to access DynamoDB. 
- CloudWatch logs+access logging  agent on the ECS, change logging to awslogs, kinesis firehose with a destination of the S# logging bucket, CloudWatch subscription for Kinesis.
53:
- Rollbakc: : CloudWatch event rules or CodeDeploy operations. Configure rule to send out SNS messagewhen the deployment fails. Configure CodeDeploy to auto rollback.
54:
- Obtain pass: from Oracle, DynamoDB : Launch EC2 instaces with an EC2 IAM role access AWS services. Retrieve the DB from Secrets Manager.

55: 
- Minimize startup time: Allow AMI to work at multiple places. Store secrets for multiple environments securely. Preconfigure the AMI by installing all the software using Systems Manager automation and configure AutoScaling to tag the instances at launch with their specific environment. Use bootstap scrip in user data to read the tags and configure settings for the environment. Use System Manager Parameter Score to store the secrets using KMS.

56: EC2 servers: ASG and ELB. Some instances are failing ELB HTTP checks.Root cause analysis on the issue: Terminating: Wait state. Amazon CloudWatch events rule for EC2 Instance-terminate Lifecycle Action and trigger AWS Lambda function that executes SSM Run Command script to collect logs push them to S3.


57: Use DynamoDB Accelerator for duplicate info, CloudFrnt send to s3

200 server nodes concurrently run: Licences + Dashboard: Update licences at Dynamo table, create AWS CLI script to launch the servers by using the parameter count with min:max instances to launch. In the data script, acquire an available license from Dynamo table. Monitor instance, in case of failure replace and manually update DynamoDB table.

Static website hosted on S3 bucket. CloudFormation to choose s3 bucket custom resource that copies content from source into the bucket. Deletion has failed bec. S3 bucket is not empty. Modify Lambda function to recursively empty the bucket.

58: Mobile game: Deploy application backend to multiple regions. 2 stage build: Successful deploy in one region invokes Lambda to copy the build artifacts to S3 bucket. After the artifact is copied it triggers a deployment pipeline in other region.

59: Alias for the Lambda function current and new versions. Configure alias to route %10 of the traffic to the new version. When the new version becomes stable, route all traffic to the new app.
 In API GW create canary deployment. Configure API GW to route %10 of the incoming traffic to Canary release. When the canary is stable promoto it to a production.

60: Use AWS CodePipeline to create a pipeline. Add a step after the source stage to make an HTTPS request to the on-premises hosted web service send the results back y putting the results in an S3 output location.

61: Use AWS CodePipeline to create a pipeline, then create a custom action type. Create a job worker for the on-premises server that polls CodePipeline for job results. Configure the pipeline to invoke the custom action after the source stage.

62: CodeDeploy custom environment variable  DEPLOYMENT_GROUP_NAME to identify which deployment group the instances is partof. Use the information to configure the log settings. Refereance the script as part of BeforeInstall lifecycle hook in the appspec.yml.
