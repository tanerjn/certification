AWS DevOps Pro(Dumpsgate-2)

- Artefacts: Publish the application artefacts to an Amazon S3 bucket, create VPC endpoint for S3. Assign IAM profile to the EC2 instances so they can read the application artefacts from the S3 bucket.
- Patching: System Manager Parameter Store to securely store credentials for each Linux and Windows server. System Manager Resource Group to remotely deploy patch updates using Parameter Store.
- Logging: Kinesis Firehose + Kinesis Data Streams to write logs to Amazon ES in the auditing account. Create CloudWatch subscription filter and stream logs from sub accounts to the Kinesis stream in the auditing account.
- Grid memory: Adding new nodes /etc/cluster/nodes.config listing the IP addresses of current mode. OpsWorks stacks to layer the server nodes of the cluster. Chef recipe that populates the content of the /etc/cluster/nodes.config file and restarts the service by using the current members of the layer. Assign the recipe to the Configure lifecycle event.
- Tagging and configuration: AWS Config record config changes and output the data to S3 bucket. QuickSight analysis of the dataset, and use the information on dashboards and mobile devices.
- EC2 ASG automation: Cloud Watch Logs subscription in an Lambda function. Configure the function to add a tag to the EC2 instance that produced the login event and mark the instance to be decommissioned. CloudWatch Events rule to trigger a daily Lambda function that terminates all the instances with tag.
- Canary testing: create a classic load balancer and AutoScaling group for blue/green environments. Use Amazon Route 53 and create weighted A records on Classic Load Balancer.
- Across multiple AZ: use Aurora with read replicas for the product catalog and additional local Aurora instances in each region for the customer information and purchases.
- Audit cost and automate infrastructure:  create CloudWatch events rule with Trusted Advisor as the source for low utilisation EC2 instances. Trigger Lambda function that filters out reported data based on tags for each team, environment, cost and store the Lambda function in S3. Set up second trigger to initiate Lambda function to reduce to underutilised instances. 
- Hybrid architecture solution in which some legacy systems remain on-premises while a specific cluster of servers moved to AWS. Reusable CloudFormation to manage EC2 ASG minimum 1 and maximum 1. Give the hostname Elastic Network Interface and AZ as stack parameter. 
- New tasks are running with old image: Restart the ECS agent.
- Security hardened AMI: Install the inspector agent in each AMI. Configure AWS Step functions to launch an EC2 instance for each operating system from the hardened AMI, tag the instance SecurityCheck:True. Once the instances are booted StepFunctions will trigger Inspector assessment for all instances with the tag security check.
- Restrict the push: Additional policy to include a deny rule for the codeCommit:GitPush. 
- CD workflow: CodeCommit: development branch to hold merged changes. Use CodeBuild to build and test the code in the development branch triggered on a new commit. Merge to the master and deploy to  production by using CodeDeploy.
- Sudden spikes: in a website load times. Check Egress security group rules and network ACLs for the VPC, check FlowLogs.
- Resilient and highly available: Elastic Beanstalk with a custom AMI including all web components. Deploy the platform by using an AutoScaling group behind AutoScaling. Use Route53 to point the application DNS record to the Elastic Beanstalk load balancer.
    - Remove AWS credentials from the environment variable.
    - Store DB_PASSWORD at safe. 
    - Use Systems Manager run command versus scp and ssh directly to the instance.
- Minimal operational effort: Implement Lambda function to read the list of proxy IP addresses from the S3 object.
- Implement Lambda function to read the list of proxy IP addresses from the S3 object and update the ELB security group to allow HTTPS only from the given IP addresses.
- Configure the S3 bucket to invoke the lambda function when the object is updated. Save the IP address list to the S3 bucket when they are changed.
- CodePipeline automation: All rejected or failed approval actions across all the pipelines.
- Launch ec2 m4 small and run script on it to check for new AMIs. If new AMIs are available, the script should update the launch configuration resource block with the new AMI ID.
- Launch the application from the CloudFormation template in the second region, which sets the capacity of the ASG group to 1. Create RDS read replica in the second region. In the second region, enable cross region replication between the original S3 bucket and a new S3 bucket. To fail over, promote the read replica as master. Update the CloudFormation stack and increase the capacity of the ASG.
- Run the application in Beanstalk with the deployment policy set to immutable. Deploy the lambda functions, DynamoDB tables, and Amazon ES domain with an CloudFormation template. Deploy the web application, Lambda functions, DynamoDB tables and Amazon ES domain in an AWS CloudFormation template. Deploy changes with an CodeDeploy blue/green deployment. 
- Media customer: least amount of steps to integrate with Slack. Integrate personal health dashboard with CloudWatch events which can invoke Lambda functions and send to Slack channel.
- Disaster recovery exercise: RTO / RPO improvement in cross region failover. Use SNS topics to receive published messages from RDS to snapshot a DB instance, create cross region snapshot copy and restore an instance from the snapshot. Use a scheduled Amazon CloudWatch events rule at a frequency matching the RPO trigger the Lambda function to snapshot a database instance. Trigger the Lambda function to create cross region snapshots when SNS topic receives messages. Configure Lambda function to restore an instance from a snapshot to trigger sending new messages published to the availability SNS topic.
- Security audit without EBS encrytpion: Create CloudFormation template that adds an AWS config managed rule for EBS encryption. Use a CloudFormation stack set to deploy the template across all accounts and regions. Store consolidated evaluation results from config rules in S3. Send notification using SNS when non-compliant resources are detected.
- Shipping orders dynamoDB. Item count to Kinesis. Logs-> Lambda functions are throttling error. Create fourth Lambda function and configure it to be the only Lambda reading from the stream. Then use it to pass the payload to the other three Lambda functions.
- Government agency storing confidential files in S3 bucket. Agency has configured federated access with AD user group to this bucket: Configure AWS Config rule to detect the configuration change and execute a Lambda to revert the change.
- Healthcare provider has hybrid architecture: includes 120 on-premise VMware running RedHat and 50 EC2 instances. Install Systems Manager agents on both the on-premises virtual machines and the EC2 instances. Enable inventory collection and configure resource data sync to an S3 bucket to analyse the data with Athena.
- Download and integrate the latest ISO Linux2 and execute the application deployment on the resulting server. Confirm all tests are consistent.
- Deployment in the new country: Code updates as commits to feature branch. Merge the commits to a release branch as features ready.
- Deploy with zero downtime: CloudFormation and Route53 record, ALB, DynamoDB, ASG. Active instance serving: AutoScaling:AutoScalingGroup:UpdatePolicy attribute with zero downtime policy. New application load balancer and AutoScaling group. Use route 53 to change the active ALB.
- AMI creation: Launch EC2 and install packer, configure packer with values defining how the image should be created. Build Jenkins pipeline to invoke the Packer build when triggered to build an AMI store. Store the AMI identification output in the DynamoDB.
- Requests are going to old ALB. Create two target groups named Blue and Green . Create a rule on the ALB pointed to a single target. Add logic to the deployment to the target group of the newly deployed ASG.
- Microservices running in Lambda read data from DynamoDB. New version of each service should be shifted incrementally. Create CodePipeline config and set up source code step to trigger when code is pushed. Set up build step to use CodeBuild to run tests, then the important CodeDeploy 10 percent every 3 minutes option.
- Production, staging and development. CodePipeline multiple stages, Lambda function to trigger CloudFormation deployments dynamically alter the UserData of the EC2 instances launched in each environment.
- Application runs behind LoadBalancer. RDS MySQL. 
- RTO/RPO improvement: Launch a replica stack of everything except RDS in different region. Create an RDS in new region and configure the new stack to the point the local RDS instance. Add new route to failover set.
- Subject as the primary key and ForumName)S3, EC2, RDS) as the sort key. Have the LSI and LastPostDate as the sort key.
- CloudFormation to deploy a three tier web application stores data in RDS MySQL Multi AZ instance. Engineer should update the EngineVersion property of the AWS::RDS::DBInstance resource type in the CloudFormation template to the latest desired version. Launch a second stack and make the new RDS  instance read replica.
- OpsWorks restarting instances for no reason: Create SNS topic and create subscription for this topic that contains the destination email address. See when the instance is unavailable: Create CloudWatch rule: specify aws.opsworks as a source and specify auto-healing the initiated-by details. Use SNS topic as target.
- Least administrative overhead: AWS Config: Identify all EC2 instances to be audited by ConfigRecording on all EC2 resources for the region. Create custom Config rule that triggers an Lambda function by using the “config-rule-change-triggered” blueprint. Modify the Lambda evaluateCompliance function to verify host placement to return a NON_COMPLIANT result if the instance is not running on an EC2 dedicated host. Use AWS Config to report to address noncompliant instances.
- S3 buckets contain encrypted secrets should be made by a trusted group of admins. Real-time automated checks to meet the requierement. Lambda triggered by S3 data events for object changes and the IAM user’s membership in an admin role.
- 5 independent Lambda functions in CodePipeline and CodeBuild deploys each Lambda in sequence. CloudWatch events ensure execution starts as quickly as possible after a change is made. Increase speed: Lambda function in parallel by runOrder.
- Version control of the CloudFormation: cross stack references in CloudFormation, and maintain several templates in version control.
- Easy rollbacks: Deploy using Beanstalk, connect to an external RDS MySQL using Beanstalk environment properties. Use Beanstalk immutable updates for application deployments.
- Error at S3 bucket read: Access denied at VPC: S3 bucket policy, VPC endpoint policy, IAM role configuration.
- Segmented architecture: Collect system Logs and application logs by using CloudWatch logs agent. Store all logs in S3 bucket in central account. Set up an S3 trigger and an Lambda function to analyse incoming logs and automatically identify anomalies. Amazon Athena to run ad hoc queries on the logs in the central account. Question 46
- CloudWatch logs to trigger lambda function. S3 analyse incoming logs. Athena to run queries in the log.
- Canary 10 percent in 5 minutes
- CodeDeploy MinimumHealthyHosts.
- SystemManager for Windows machines: IAM service role for Systemmanager ssm.amazonaws.com to execute AssumeRole. Previously obtained activation code and activation IDS, download and install SSM Agent Hybrid instances show with -mi prefix. 
- DNS failover for distributed web application disaster recovery. Configure Route 53 to provide DNS routing. Ensure firewall and routing rules, proxy. Governing amazon route set it to failover distribute traffic DNS entries. 
- ECS Cluster: awslogs, ALB to point S3, Kinesis Firehose to destination CloudWatch subscription.
- ECS Cluster to run workloads on the cluster with ALB on the front end, using multiple target groups. Collect logs and send to S3 bucket. Install CloudWatch logs logging on the ECs instances, change logging to awslogs. Enable access loging on the ALB and point it directly to  S3 logging. Create Kinesis Firehose with destination S3.
- CodeDeploy CloudWatch events rule to send SNS message when deployment fails. CodeDeploy to automatically rollback when the deployment fails.
- Launch EC2 instances with an EC2 IAM role to access AWS services. Retrieve the DB credentials from Secrets Manager.
- Deployment Strategy: Preconfigure the AMI by installing all the software using Systems Manager and configure Auto Scaling tag the instances at launch with their specific environment. Use a bootstrap script in user data to read the tags and configure for the environment. Use Systems Manager Store for the secrets using KMS.
- ELB check instance termination: AutoScaling lifecycle hooks to put instances in a Terminating:Wait state. Create an CloudWatch Events rule for EC2 instance terminate lifecycle action.
- Use DynamoDB accelerator to cache repeated read requests to DynamoDB and Amazon CloudFront to cache images stored in S3.
- 200 server nodes concurrently: upload licences to DynamoDB. Create script to launch the servers by using the parameter —count, with min:max instances to launch. In the user data script, acquire an available license from the DynamoDB table, monitor each instance and in case of failure replace the instance and manually update the DynamoDB.
- Static website on S3: Deletion has failed bec. S3 bucket is not empty. Modify custom resources Lambda function code to recursively empty the bucket when RequestType is Delete.
- Deploy to multiple regions. Any update to the code repo triggers two stage build and deployment pipeline. One region successful deployment invokes the lambda function to copy the build artefacts to an S3 bucket in another region. After the arfefact is copied it triggers a deployment pipeline in the new region.
- Create alias for lambda pointing to the Lambda endpoints for the old and new versions. Configure route 53 to route %10 of incoming traffic to the new version. New version becomes stable-> update the alias to route all traffic to the new one. API GW, create canary release deployment by adding canary settings to the stage of a regular deployment. Configure API GW to route %10 of the incoming traffic to the canary release. Canary release gets stable->promote it to production.
- Security code analysis: CodePipeline to create a pipeline then create a custom action type. Create job worker for the on premises server that polls CodePipeline for job requests initiates the tests and returns the results. Configure the pipeline to invoke the custom action after the source stage.
- Apache app to CodeDeploy env var DEPLOYMENT_GROUP_NAME configure log level settings reference script BeforeInstall lifecycle. 
- Chef recipes stored in private git: Configure OpsWorks stacks and use custom Chef cookbooks. Add layer in OpsWorks for the Node.js application. Configure time based instances and attach an EC2 IAM role to access DynamoDB. 
- CloudWatch logs+access logging  agent on the ECS, change logging to awslogs, kinesis firehose with a destination of the S# logging bucket, CloudWatch subscription for Kinesis.
53:
- Rollbakc: : CloudWatch event rules or CodeDeploy operations. Configure rule to send out SNS messagewhen the deployment fails. Configure CodeDeploy to auto rollback.
54:
- Obtain pass: from Oracle, DynamoDB : Launch EC2 instaces with an EC2 IAM role access AWS services. Retrieve the DB from Secrets Manager.

55: 
- Minimize startup time: Allow AMI to work at multiple places. Store secrets for multiple environments securely. Preconfigure the AMI by installing all the software using Systems Manager automation and configure AutoScaling to tag the instances at launch with their specific environment. Use bootstap scrip in user data to read the tags and configure settings for the environment. Use System Manager Parameter Score to store the secrets using KMS.

56: EC2 servers: ASG and ELB. Some instances are failing ELB HTTP checks.Root cause analysis on the issue: Terminating: Wait state. Amazon CloudWatch events rule for EC2 Instance-terminate Lifecycle Action and trigger AWS Lambda function that executes SSM Run Command script to collect logs push them to S3.


57: Use DynamoDB Accelerator for duplicate info, CloudFrnt send to s3

200 server nodes concurrently run: Licences + Dashboard: Update licences at Dynamo table, create AWS CLI script to launch the servers by using the parameter count with min:max instances to launch. In the data script, acquire an available license from Dynamo table. Monitor instance, in case of failure replace and manually update DynamoDB table.

Static website hosted on S3 bucket. CloudFormation to choose s3 bucket custom resource that copies content from source into the bucket. Deletion has failed bec. S3 bucket is not empty. Modify Lambda function to recursively empty the bucket.

58: Mobile game: Deploy application backend to multiple regions. 2 stage build: Successful deploy in one region invokes Lambda to copy the build artifacts to S3 bucket. After the artifact is copied it triggers a deployment pipeline in other region.

59: Alias for the Lambda function current and new versions. Configure alias to route %10 of the traffic to the new version. When the new version becomes stable, route all traffic to the new app.
 In API GW create canary deployment. Configure API GW to route %10 of the incoming traffic to Canary release. When the canary is stable promoto it to a production.

60: Use AWS CodePipeline to create a pipeline. Add a step after the source stage to make an HTTPS request to the on-premises hosted web service send the results back y putting the results in an S3 output location.

61: Use AWS CodePipeline to create a pipeline, then create a custom action type. Create a job worker for the on-premises server that polls CodePipeline for job results. Configure the pipeline to invoke the custom action after the source stage.

62: CodeDeploy custom environment variable  DEPLOYMENT_GROUP_NAME to identify which deployment group the instances is partof. Use the information to configure the log settings. Refereance the script as part of BeforeInstall lifecycle hook in the appspec.yml.

63: Predictable peak traffic times. Instances to scale up only peak times. Standort Node.js application. Configure OpsWorks stacks and custom Chef cookbooks. Git repo info. Custom recipe to deploy application in steps. Configure time based instances and attach an EC2 IAM role that provides permission to access DynamoDB.

64: Health dashboard: AWS Health API to automate remediation actions for issues with the health of AWS. Delete IAM access key and send notification to the security team: Step functions to delete the IAM key then use SNS to send notificcation to the security team. Create CloudWatch Events rule with an aws.health event source and the AWS_RISK_CREDENTIALS_EXPOSED event; set the target to CloudWatch events.

65: Security team depends on CloudTrail to detect sensitive isses in the copany's account. Auto-remediate CloudTrail turned off: CloudWatch Events rule fo the CloudTrail StopLogging event. Lambda function that uses the SDK to call StartLoggin on the resource in which StopLogging was called. Add the Lambda function ARN as a target to the CloudWatch Events rule.

66: CloudTrail files are not tampered with after being created. IAM to restric access to specific trails. Security team wants to ensure they can trace the integrity of each file and make sure there is no tampering. Enable CloudTrail file integrity feature. Use the digest file created by CloudTrail to verify the integrity.

67: Serverless architecture for mobile and web apps with API gateway. Fully automate the deployment based on the CodeCommit. 

1. Seperate environment pipelines for testing and production.
2. Automatic deployment that occurs for test environments only.

Two CodePipeline for test and production environments. Configureproduction pipeline to have manual approval step. Create CodeCommit with a branch for each environment. Set up each CodePipeline to retrivethe source code from the appropriate branch in the repository. Set up the deployment step to deploy the Lambda functions with CloudFormation.

68: Test action after the last deploy action of the pipeline. configure the action to use CodeBuild to perform the reqired tests. if tests are succesfil, mark the acion as successfil. Add manual approval action uses SNS to notify the team over slack SNS.

69: Data must be encrypted in transit: 
	Data must be replicated in at least two locations that are 500 miles apart.

	Primary and secondary S3 buckets in seperate regions 500 miles apart. Use IAM role to enforce access to the buckets only through HTTPS. Use bucket policy to enforce S3 managed keys(SSE-S3) on all objects uploaded to the bucket. Configure cross region replication between the two buckets.

70: Use Application Load Balancer and blue/green deployment. Associate the ASG and target deployment group with. Automatically copy Auto Scaling group, use CodeDeployDefault.HalfAtTime as the deployment configuration. Use AppSpec.yml file to delete temporary files. Use BeforeAllowTraffic to see if green deployment works.

71: 12 instances across 3 availability zones. New instances can be started from AMI image. Each E2 instance has 30% utilisation during business hours %10 after business hours. Immediate spike at first business hours. Reduce cost while retaining the same reliability.

Create ASG using the AMI image with a scaling action based on the ASG CPU utilisation with a target of %75. Create a scheduled action for the group to adjust the minimum number of instances to three after business hours and reset to 6 during business hours.

72. Finance team transactions for an e-commerce platform handled by the Microservices on multiple EC2 instances. We should know the requests falls below a threshold. Solution: Have the team successfully log transactions to an application log. Set up the CloudWatch agent on each instance, create CloudWatch alarm when the threshold is breached, Use SNS to notify the team.
73. Migrating application to AWS runs on single EC2. DB: Aurora. CloudWatch events rule to trigger an AWS Lambda function to start a new EC2 instance in an available AZ when the instance status reaches a failure state. Create Aurora DB with read replica in a second AZ and promote it to a primary DB when the primary DB fails.
74. 3 environments: Development, pre-production production. Several misconfigured and nonfunctional code into production resulting in user disruption and downtime. Functional issues during deployment process: 1. CodeBuild to add a test action to the pipeline to replicate user activities and ensure results. Add CodeDeploy action in the pipeline to deploy the latest version of the development code t preproduction. Manual approval action in the pipeline so that the QA team can test and confirm the expected functionality. After the manual approval-> second CodeDeploy action that deploys the approved code to the production environment.
75. PHP application hybrid deployment, CodeDeploy to deploy application packages to the instances. Store DB credentials on AWS Systems Manager Parameter store, Secure String data type. Define IAM policy for allowing access and decrypt only the database credentials. Attach IAM policy to the role associated to the instance profile for CodeDeploy managed instance, and to the role used for on-premise instance registration.
76. Create CodeCommit repository for each project, use the master branch for production code and create testing branch for code deployed to testing. Use feature branches to develop new features and pull requests to merge code to testing and master branches.
77. Create AWS CodePipeline that pulls code from the CodeCommit repository. Create alpha, beta and production stages with Jenkins servers.
78. EC2 AutoScaling extensively to provide an excellent customer experience while minimising the number of running EC2 instances. Self-hosted Puppet environment in the application layer manages the configuration of the instances. IT manager wants the lowest licensing costs, wants to ensure that whenever the EC2 AutoScaling group scales down, removed EC2 are deregistered from Puppet master. Instance launch time, use EC2 data to deploy the AWS CodeDeploy agent. Use CodeDeploy to install Puppet agent. When ASG scales out, run a script to register the newly deployed instances to the Puppet master. When the ASG scales in, use the EC2 AutoScaling E2_INSTANCE_TERMINATING lifecycle hook to trigger reregistration from the Puppet master.
79. Customers storing AWS Access Keys in the configuration files pushed to Git repo hosting service. Configure Trusted Advisor and create CloudWatch events that uses Trusted Advisor as the event source. Configure CloudWatch Events rules to invoke a Lambda function as the target. If the Lambda function finds the exposed access keys, then have it disable the access key so that it can not be used.
80. Flow log for the production VPC. Create a new rule using AWS Config that is triggered by configuration changes of resources of type ‘EC2:VPC’. As part of configuring the rule, create an AWS Lambda function that looks up flow logs for a given VPC. If the VPC flow logs are not configured, return a ‘NON_COMPLIANT’ status and notify the security organisation.
81. DevOps Engineer needs to deploy scalable three-tier Node.js application in AWS. The application must have zero downtime during deployments and rollback easily to previous versions. Other applications will also connect to the same MySQL backend database. CIO has provided the guidance for logging. View all current web access server logs, search and filter web and application logs in real time, retain log data for 3 months: Deploy the authentication using Beanstalk, configure the environment type for Elastic Load Balancing and Auto Scaling. Create MySQL instance outside the Elastic Beanstalk stack. Configure the Elastic Beanstalk log options to stream logs to CloudWatch logs. Set retention for 90 days.
82. CloudFormation template: Custom resource when Lambda function with the DependsOn attribute specifying the S3 bucket and an IAM role. Write the Lambda function to delete all objects from the bucket when RequestType: Delete.
83. Already running workloads on EC2 instances, AWS has been adopted incrementally with no central governance. Assess how well the existing deployments comply with the following requirements: AWS Config, Amazon Inspector.
84. Critical application running in AWS Region: ELB and EC2 instances, custom AMI that contains its application. AMI is changed frequently. Automate the copying of the AMI to the backup region. Create an AWS Lambda function that can create a launch configuration and assign it to an already created AutoScaling group. Set the ASG maximum size to 0 and only increase it with the Lambda function during a failure. Trigger Lambda function in the event of a failure.
85. Legacy web application stores logs in text format. Security requirement is to search application access events and correlate them with access data from different systems. Install Kinesis Agent on the application server, configure it to monitor the log files, forward events to ES for analysis. Use ElasticSearch API for querying data.
86. DB on a single EC2 in a development environment. Data is stored on separate EBS volumes attached to EC2. Amazon Route 53A record to point EC2. Automate recovery when an instance or AZ fails. RTO:4 hours, RPO:12 hours. Run the DB on two separate EC2 instances in different AZs. Configure one of the instances as a master and the other as standby. Setup replication between master and standby. Point the Route53 record to the master. Configure an CloudWatch Events rule to invoke EC2 instance. If the terminated instance was the active node, the function promotes the standby to master and points the Route53 record to it.
87. Assess security vulnerabilities client’s application and propose plan to remediate all identified issues. S3 for storage, ASG for EC2 behind ELB with attached EBS storage and MySQL database. Also several Lambda functions communicate directly with the RDS database using connection string statements in the code. Top security threat: No encryption at rest. Enable Secure Sockets Layer(SSL) on the load balancer, ensure AWS Lambda is using SSL and configure the application to force SSL for incoming RDS connections. Configure Amazon Inspector agents on EC2 instances to report on insecure encryption ciphers.
88. Zero day vulnerability was found in OpenSSL requiring the immediate patching of a production web fleet, running on Linux. Currently, monthly OS updates are performed and deployment with ASG launch config. Use EC2 Run Command to issue a package update command to all running production instances and update the AMI for further deployments.
89. Production application workload in a single AWS account uses Route53. EBS and RDS. Security team wants the application workload to fail over to a new AWS account. Security team wants to block all access to the original account immediately, with no access to any AWS resources in the original AWS account, during forensic analysis. Most cost effective way to prepare to a failover: Migrate the Route 53 configuration to a dedicated AWS account. Mirror Beanstalk configuration in a different account. Enable RDS DB. 
90. Two teams are working together on different portions of an architecture and are using CloudFormation to manage resources. Operating System team uses CloudFormation stack to create an AWS CodePipeline that builds new AMIs. The team then places the AMI ARNs as parameter of type SSM in their CloudFormation stack to obtain the most recent AMI ARN from the Parameter Store.
91. Service limit alerts regarding the number of S3 buckets. Pipeline to reduce S3 bucket sprawl alerts: New pipelines by using the AWS API or AWS CLI, configure them to use a single S3 bucket with separate prefixes for each project.
92. Startup company is developing a web application on AWS. It plans to use RDS for persistence and deploy the application to EC2 with an ASG. Company would like to separate the environments for development, testing and production. Create a property file for each environment to include specific configuration. Create a private S3 bucket and save the property files in the bucket. Save the encrypted passwords in the AWS Systems Manager Parameter Store. Create an environment tag for the EC2 instances and tag the instances respectively. The application will read the needed property values from the environment-specific property file in the S3 bucket and the parameter store.
93. CodeDeploy across a fleet of EC2 instances in EC2 ASG group. Associated CodeDeploy which is integrated with EC2 ASG configured to perform in-place deployments with CodeDeployDefault.OneAtATime. During an ongoing new deployment, Engineer discovers 2/5 instances have the previous application deployed. Other three have the newest application revision. EC2 ASG launched two new instances while the deployment had not yet finished, causing the previous to be deployed on the affected instances.
94. Three tier web application built on single CloudFormation. Stored data in RDS MultiAZ DB instance with read replicas. Route 53 manages the public DNS. Create a workflow to mitigate a failed software deployment by rolling back changes in the production environment when a software cutover occurs for new application software. CloudFormation to deploy staging environment and configure the Route53 DNS with weighted records. During cutover, increase the weight distribution to have more traffic directed to the new staging environment as workloads are successfully validated. Keep the old production environment in place until the new staging environment handles all traffic.
95. Compromised IAM access keys from leaked and compromised IAM access keys. Identify users, revoke permission, sending notifications-> Trusted Advisor identify compromised keys. Create CloudWatch Events rule with Trusted Advisor as the event source, Lambda and SNS as target. Lambda to delete compromised IAM access keys and SNS to notify the Security team.
96. ECS Docker container: All EBS volumes and ECS cluster must be encrypted. Rolling updates will be made to the cluster instances, all instances should be drained of all tasks before termination. Copy default template that ECS uses to deploy cluster instances. Modify the template  resource EBS configuration setting to set ‘Encrypted’. ASG LifeCycle hook backed by Lambda to use the SDK to mark instance as DRAINING. Prevent lifecycle hookworm completing until the running tasks on the instance are zero.
97. Multiple AWS accounts storing sensitive information. Security team to detect anomalous account and network activities SIEM: Enable GuardDuty in every account. Configure the security account as the GuardDuty Administrator for every member account using invitation. Create CloudWatch rule in the security account to send all findings to Kinesis Firehose, push findings to the S3 bucket.
98. CodeDeploy to improve monitoring: CloudWatch Events for CodePipeline and CodeDeploy, create Lambda function to evaluate deployment issues. Create SNS topic to notify.
99. EC2 behind ALB across multiple AZs. Application stores data in RDS MySQL MultiAZ instance. Add health check to Route53, use Lambda-> CloudWatch events->Promote to RDS read replica. New Application Load Balancer and E2 ASG in the disaster recovery region. Deploy read replica of the RDS instance in the disaster recovery region.
100. EFS: Lambda with CloudWatch Events rule for scheduling the start/stop of backup activity. Run backup scripts on EC2 in ASG. Use lifecycle hooks and the SSM RUN Command on EC2 for uploading backup logs to S3. Use SNS to notify admins with backup activity metadata.
101. Fn:Import for intrinsic functions to get VPC and subnet values. CountInput to indicate the number of environments needed. Use UpdateStackSet command to update existing development environments.
102. Change the setting for the ASG group health check from EC2 to Elastic Load Balancing and increase the capacity of the group.
103. Enable AutoScaling for the DynamoDB tables that used by the application. Configure Load Balancer to automatically adjust the target group based on the current load.
104. Use extensions configure the option setting MeasureName to CPUUtilization within the aws:autoscaling:trigger namespace.
105. Query information from Beanstalk: Use CloudWatch Logs subscription to send the log data to Kinesis Data Firehose stream that has an S3 bucket destination. Use Athena to query the log data from the bucket.
106. No server side code required. Open Web Application Security Project(OWASP) to secure HTTPS response headers. S3 bucket configuration for website hosting. CloudFront distribution that refers to this S3 bucket, with the origin response event set tot trigger a Lambda@Edge Node.js function to add in the security headers.
107. Improve the scalability of Beanstalk environment. 





